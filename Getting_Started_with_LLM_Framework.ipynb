{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-JIM6baT6N6"
      },
      "outputs": [],
      "source": [
        "!pip install -qq langchain-google-genai langchain-openai langchain-groq langchain-cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "account_center = pd.read_excel('/content/drive/MyDrive/Celerates MSIB/ALL Dataset/API key Gemini.xlsx')\n",
        "account_center.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXtyik6hyBxo",
        "outputId": "505a35e4-ffab-4e94-d583-48c42bfb0f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['api_name', 'api_key'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini"
      ],
      "metadata": {
        "id": "5SNEBQFUzquM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_api_key(api_name):\n",
        "  return str(account_center[account_center[\"api_name\"]==api_name]['api_key'].values[0])"
      ],
      "metadata": {
        "id": "4dPhEbHey9Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.7,\n",
        "    api_key=get_api_key('Gemini')\n",
        "    )\n",
        "llm.invoke(\"hi how are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCiGYDLlz3BC",
        "outputId": "da1a6247-51cf-487b-af16-d77471f15f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I'm doing well, thank you for asking!  How are you today?\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-1ddc5399-cb93-44ea-9de8-f183a6773e72-0', usage_metadata={'input_tokens': 6, 'output_tokens': 18, 'total_tokens': 24, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grammar Correction\n",
        "prompt_text = '''SYSTEM\n",
        "You will be provided with statements, and your task is to convert them to standard English.\n",
        "USER\n",
        "She no went to the market.\n",
        "'''\n",
        "llm.invoke(prompt_text)"
      ],
      "metadata": {
        "id": "Amv4lU6s0BfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a121224-ec74-4b8f-fcd0-0cd6c282a9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='She did not go to the market.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-1202eb4c-0e88-43c8-848d-acb169dff01f-0', usage_metadata={'input_tokens': 32, 'output_tokens': 9, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}